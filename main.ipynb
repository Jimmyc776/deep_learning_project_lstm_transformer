{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from stock_dataloader import create_stock_dataloader\n",
    "from lstm import StockLSTM\n",
    "from transformer import StockTransformer\n",
    "from model_trainer import train_model, save_model, load_model\n",
    "from evaluation import evaluate_model\n",
    "from plots import plot_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader\n",
    "\n",
    "# Hyperparameters\n",
    "SEQ_LEN = 1250          # default 1250; window for set of time-series data points\n",
    "BATCH_SIZE = 128        # default 128; uses 25-30% of 12GB NVIDIA GeForce RTX 4070 GPU\n",
    "STOCKS_PER_BUCKET = 13  # default 13; number of stocks per category bucket\n",
    "TRAIN_PER_BUCKET = 10   # default 10; number of training stocks per category bucket\n",
    "\n",
    "stock_csv = 'selected_stocks_data.csv'\n",
    "metadata_csv = 'selected_stocks_quality.csv'\n",
    "stock_dataloader = create_stock_dataloader(stock_csv, metadata_csv, seq_len=SEQ_LEN, batch_size=BATCH_SIZE,\n",
    "                                           stocks_per_bucket=STOCKS_PER_BUCKET, train_per_bucket=TRAIN_PER_BUCKET)\n",
    "train_dataloader = stock_dataloader['train_loader']\n",
    "train_dataset = stock_dataloader['train_dataset']\n",
    "train_tickers = stock_dataloader['train_tickers']\n",
    "eval_dataloader = stock_dataloader['eval_loader']\n",
    "eval_dataset = stock_dataloader['eval_dataset']\n",
    "eval_tickers = stock_dataloader['eval_tickers']\n",
    "eval_scalers = stock_dataloader['eval_scalers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c98d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM Model\n",
    "\n",
    "# Hyperparameters\n",
    "INPUT_SIZE = 1          # default 1; based on data\n",
    "HIDDEN_SIZE = 64        # default 64; analogous to D_MODEL; increase to 128 if underfitting\n",
    "NUM_LAYERS = 2          # default 2, re-evaluate if underfitting\n",
    "DROP_OUT = 0.2          # default 0.2; re-evaluate if overfitting\n",
    "\n",
    "lstm_model = StockLSTM(input_size=INPUT_SIZE,\n",
    "                  hidden_size=HIDDEN_SIZE,\n",
    "                  num_layers=NUM_LAYERS,\n",
    "                  dropout=DROP_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b85af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Transformer Model\n",
    "\n",
    "# Hyperparameters\n",
    "INP_DIM = 1             # default 1; based on data\n",
    "D_MODEL = 64            # default 64; analogous to HIDDEN_SIZE; re-evaluate if underfitting\n",
    "N_HEADS = 4             # default 4; 64/4 = 16 - standard ratio\n",
    "N_LAYERS = 3            # default 3; re-evaluate if underfitting\n",
    "DIM_FEEDFORWARD = 256   # default 256; 4x D_MODEL is standard\n",
    "DROPOUT = 0.1           # default 0.1; re-evaluate if overfitting\n",
    "OUTPUT_DIM = 1          # default 1; based on data - next-day closing price\n",
    "MAX_LEN = 1500           # default 500; should be > SEQ_LEN\n",
    "\n",
    "transformer_model = StockTransformer(inp_dim=INP_DIM,\n",
    "                         d_model=D_MODEL,\n",
    "                         n_heads=N_HEADS,\n",
    "                         n_layers=N_LAYERS,\n",
    "                         dim_feedforward=DIM_FEEDFORWARD,\n",
    "                         dropout=DROPOUT,\n",
    "                         output_dim=OUTPUT_DIM,\n",
    "                         max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "# Hyperparameters\n",
    "NUM_EPOCHS = 50         # default 50; increase if underfitting\n",
    "LEARNING_RATE = 0.0001  # default 0.0001; 1e-3 exploded\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_choice = 'Transformer'   # Select 'LSTM' or 'Transformer'\n",
    "model_save_name = f'Stock{model_choice}_ModelFull'\n",
    "model_save = True\n",
    "model_load = True\n",
    "\n",
    "print(f\"Training {model_choice} model on device: {DEVICE}\")\n",
    "if model_choice == 'LSTM':\n",
    "    if model_load:\n",
    "        try:\n",
    "            trained_model = load_model(f'models\\{model_save_name}')\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "            trained_model = train_model(lstm_model, train_dataloader, num_epochs=NUM_EPOCHS, learning_rate=LEARNING_RATE, device=DEVICE)\n",
    "    else:\n",
    "        trained_model = train_model(lstm_model, train_dataloader, num_epochs=NUM_EPOCHS, learning_rate=LEARNING_RATE, device=DEVICE)\n",
    "    if model_save:\n",
    "        save_model(trained_model, save_name=model_save_name)\n",
    "elif model_choice == 'Transformer':\n",
    "    if model_load:\n",
    "        try:\n",
    "            trained_model = load_model(f'models\\{model_save_name}')\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "            trained_model = train_model(transformer_model, train_dataloader, num_epochs=NUM_EPOCHS, learning_rate=LEARNING_RATE, device=DEVICE)\n",
    "    else:\n",
    "        trained_model = train_model(transformer_model, train_dataloader, num_epochs=NUM_EPOCHS, learning_rate=LEARNING_RATE, device=DEVICE)\n",
    "    if model_save:\n",
    "        save_model(trained_model, save_name=model_save_name)\n",
    "else:\n",
    "    raise ValueError(f\"{model_choice} is an invalid model choice. Please select 'LSTM' or 'Transformer'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d72a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluate_model(trained_model, eval_dataloader, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time-series\n",
    "\n",
    "# From CSV\n",
    "plot_time_series(\"selected_stocks_data.csv\", tickers=['AMZN', 'EBAY', 'COKE'])\n",
    "\n",
    "# Separate plots\n",
    "plot_time_series(\"selected_stocks_data.csv\", tickers=['AMZN', 'EBAY', 'COKE'], separate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd55230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to update this plotting for model predictions vs actuals #\n",
    "import numpy as np\n",
    "trained_model.eval()\n",
    "trained_model.to(DEVICE)\n",
    "\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in eval_dataloader:\n",
    "        batch_x, batch_y = batch_x.to(DEVICE), batch_y.float().to(DEVICE)\n",
    "        pred = trained_model(batch_x)  # Shape: [batch_size, 1]\n",
    "        predictions.append(pred.cpu())\n",
    "        actuals.append(batch_y.cpu())\n",
    "\n",
    "# 2. Concatenate all predictions\n",
    "all_predictions = torch.cat(predictions).squeeze().numpy()  # 1D array\n",
    "all_actuals = torch.cat(actuals).squeeze().numpy()          # 1D array\n",
    "\n",
    "# 3. Plot model vs actual\n",
    "plot_time_series(all_actuals, tickers=[\"Actual\"])\n",
    "plot_time_series(all_predictions, tickers=[\"Predicted\"])\n",
    "\n",
    "# 4. Plot TOGETHER (1D tensor stacking)\n",
    "combined = np.stack([all_actuals, all_predictions], axis=0)  # [2, N]\n",
    "plot_time_series(combined, tickers=[\"Actual\", \"Predicted\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
